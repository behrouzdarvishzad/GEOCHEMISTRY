{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "678ab5de-5ba7-43d0-9cc2-4f967fe0d2a0",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "Modern geochemical and environmental datasetsâ€”especially those generated by ICPâ€‘MS, ICPâ€‘OES, or XRF instrumentsâ€”require rigorous Quality Control (QC) before any interpretation or modelling can begin. Analytical workflows often include thousands of samples and dozens of analytes, along with standards, blanks, duplicates, and censored (belowâ€‘detectionâ€‘limit) values.\n",
    "\n",
    "This notebook builds a lightweight, transparent, and fully reproducible QC toolkit in Python, designed to mirror the core checks used in professional laboratories and mining operations. The goal is to demonstrate how QC logic can be automated using clean, readable code that scales to multiâ€‘element datasets.\n",
    "\n",
    "The notebook covers:\n",
    "\n",
    "- Detection limits & censored data handling  \n",
    "Configurable substitution methods (DL/2, DL/âˆš2, zero).\n",
    "\n",
    "- Standards QC  \n",
    "%Bias calculations and pass/fail evaluation against certified values.\n",
    "\n",
    "- Blanks QC  \n",
    "Contamination checks using configurable thresholds (e.g., 5Ã— DL).\n",
    "\n",
    "- Zâ€‘scores & Shewhartâ€‘type control rules  \n",
    "Simple drift detection for monitoring instrument stability.\n",
    "\n",
    "- QC summary functions  \n",
    "A unified structure for flagging precision, accuracy, contamination, and drift.\n",
    "\n",
    "Each function is modular and easy to integrate into larger pipelines, making this notebook a practical foundation for realâ€‘world assay validation, exploration geochemistry, or environmental monitoring.\n",
    "\n",
    "#### Using Dictionaries for Geochemical Assay Data\n",
    "Python dictionaries are a convenient way to store assay results by element, especially when working with multiâ€‘element geochemical datasets. Each key represents an element (and its unit), and each value stores the corresponding assay result.\n",
    "\n",
    "Dictionaries allow us to:\n",
    "\n",
    "- Access any elementâ€™s assay quickly\n",
    "- Keep units visible and explicit (e.g., ppm, %, ppb)\n",
    "- Organize multiâ€‘element data in a clean, readable structure\n",
    "- Pass assay sets into QC or geochemical functions easily"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ff205ff-e77d-47b0-8299-f13f65fa32b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.25\n"
     ]
    }
   ],
   "source": [
    "# Dictionary storing assay values for multiple elements\n",
    "assay = {\"Au_ppm\": 1.25, \"Ag_ppm\": 3.1, \"Cu_pct\": 0.42}\n",
    "\n",
    "# Accessing the gold value\n",
    "print(assay[\"Au_ppm\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7c5681-f3f3-40f3-8849-b5f5414a43b9",
   "metadata": {},
   "source": [
    "Assay datasets often contain dozens of elements.\n",
    "\n",
    "Dictionaries allow us to reference each element by name, rather than relying on column positions.\n",
    " \n",
    "This structure integrates naturally with QC functions such as:\n",
    "\n",
    "- RPD for duplicates\n",
    "- Detection limit checks\n",
    "- Standard and blank QC\n",
    "- ALR/CLR transformations\n",
    "- Interval compositing\n",
    "- This makes dictionaries a simple but powerful building block for building a geochemical QC toolkit in Python.\n",
    "\n",
    "#### List Comprehensions in Python (Geochemistry Example)\n",
    "A list comprehension is a compact and readable way to create a new list by transforming the elements of an existing list.\n",
    "It replaces longer forâ€‘loops with a single clean expression.\n",
    "\n",
    "This is especially useful in geochemistry when converting units or applying the same transformation to many assay values.\n",
    "\n",
    "##### Example: Converting ppm to percent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5dfea6e-ca96-440c-8e76-08d52a15ed21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2e-05, 5e-05, 0.0001]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppm = [0.2, 0.5, 1.0]\n",
    "percent = [x / 10000 for x in ppm]  # 1% = 10,000 ppm\n",
    "percent\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5645f6-7d3c-4030-b601-1896468fe3e1",
   "metadata": {},
   "source": [
    "ppm is a list of values in parts per million.\n",
    "\n",
    "The list comprehension [x / 10000 for x in ppm] means:\n",
    "\n",
    "1- Take each value x in the list ppm\n",
    "\n",
    "2- Divide it by 10,000 to convert ppm â†’ percent\n",
    "\n",
    "3- store the result in a new list called percent\n",
    "\n",
    "#### Handling Exceptions in Python: Safe Division Function\n",
    "In real geochemical workflows, division by zero can happen easilyâ€”for example when calculating ratios, enrichment factors, or percent differences where the denominator might be zero or below detection limit.\n",
    "\n",
    "A clean way to prevent your code from crashing is to use exception handling.\n",
    "\n",
    "The function below demonstrates a simple and practical pattern:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2278d6d9-7ad6-4fed-a186-33f9761c8bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def safe_div(a: float, b: float) -> float:\n",
    "    try:\n",
    "        return a / b\n",
    "    except ZeroDivisionError:\n",
    "        return float(\"nan\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b990926e-6184-4b89-82e4-e0cdced7a184",
   "metadata": {},
   "source": [
    "- It attempts to divide a by b.\n",
    "- If b is zero, Python would normally raise a ZeroDivisionError.\n",
    "- The try/except block catches that error and returns NaN instead of stopping the program.\n",
    "\n",
    "This pattern is useful when:\n",
    "\n",
    "- Calculating RPD where (a + b) might be zero\n",
    "- Computing ratios (e.g., Cu/Zn, As/Sb)\n",
    "- Working with detection limits where values may be zero\n",
    "- Running QC pipelines where you want the script to continue even if some values are invalid\n",
    "- Returning NaN keeps the workflow stable and allows downstream functions (pandas, numpy, plotting) to handle missing or invalid values gracefully.\n",
    "\n",
    "#### Geochemistry Helper Functions â€” Unit Conversions (ppm â†” % â†” g/t)\n",
    "Unit conversions are a routine part of geochemical data processing. Assay datasets often mix units such as ppm, percent, and g/t, and converting between them cleanly is essential for QC, reporting, and downstream calculations.\n",
    "\n",
    "The functions below provide simple, readable conversions commonly used in exploration and mining geochemistry.\n",
    "\n",
    "##### 1. ppm â†’ percent\n",
    "10,000 ppm = 1%  \n",
    "##### 1% = 1/100 = 10,000 ppm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ec3ed4b-eb08-4110-9d3f-12521d538aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppm_to_percent(ppm: float) -> float:\n",
    "    \"\"\"Convert ppm to percent. 10,000 ppm = 1%.\"\"\"\n",
    "    return ppm / 10000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a3ea00-3ecc-4568-bb9b-70f717e97965",
   "metadata": {},
   "source": [
    "##### 2. percent â†’ ppm\n",
    "The inverse conversion:\n",
    "##### ppm = percent Ã— 10,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c6822731-fe5a-42e5-aa9a-58fc9e33d384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def percent_to_ppm(percent: float) -> float:\n",
    "    \"\"\"Convert percent to ppm.\"\"\"\n",
    "    return percent * 10000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4c8c15c-9403-4603-9231-325da5a1ef86",
   "metadata": {},
   "source": [
    "##### 3. ppm â†’ g/t (for Au/Ag)\n",
    "For solid rock samples, 1 ppm â‰ˆ approximately equals 1 g/t, especially for precious metals such as gold and silver.\n",
    "- ppm = mg/kg\n",
    "- g/t = g per tonne\n",
    "- 1 mg/kg = 1 g/t\n",
    "- So the conversion is effectively an identity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "82f9bafb-9aea-4c8d-b7c8-f02b6b548f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ppm_to_gpt(ppm: float) -> float:\n",
    "    \"\"\"For Au/Ag: ppm â‰ˆ g/t in solids (1 ppm ~ 1 g/t).\"\"\"\n",
    "    return ppm  # identity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3127d0e-fbb1-4818-b997-0a70de3ceb4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42\n",
      "4200.0\n",
      "1.5\n"
     ]
    }
   ],
   "source": [
    "print(ppm_to_percent(4200))    \n",
    "print(percent_to_ppm(0.42))    \n",
    "print(ppm_to_gpt(1.5))         \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bd1d42-7284-4d22-816b-609a052fcfe3",
   "metadata": {},
   "source": [
    "Usage:\n",
    "- ICP-MS and ICP-OES outputs often mix ppm and percent\n",
    "- Precious metals (Au, Ag) are typically reported in g/t\n",
    "- Base metals (Cu, Pb, Zn) may appear in % or ppm depending on grade\n",
    "- QC checks (standards, duplicates, blanks) require consistent units\n",
    "- Compositing and metal-content calculations depend on correct units\n",
    "\n",
    "#### Relative Percent Difference (RPD) â€” Precision Check for Duplicate Assays\n",
    "The Relative Percent Difference (RPD) is one of the most widely used metrics in geochemical QA/QC for evaluating precision between duplicate samples.\n",
    "It measures how closely two assay values agree with each other, expressed as a percentage.\n",
    "\n",
    "A low Relative Percent Difference- RPD- means the duplicate pair is consistent; a high RPD suggests poor precision or potential analytical issues.\n",
    "$$\n",
    "RPD = \\frac{|a - b|}{\\frac{a + b}{2}} \\times 100\n",
    "$$\n",
    "\n",
    "- ð‘Ž = primary assay\n",
    "- ð‘ = duplicate assay\n",
    "- The denominator uses the mean of the two values to normalize the difference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f597741d-0b58-48f6-b119-474d4b67a8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.921568627450984\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def rpd(a: float, b: float) -> float:\n",
    "    \"\"\"Relative Percent Difference: abs(a - b) / ((a + b)/2) * 100.\"\"\"\n",
    "    if (a + b) == 0:\n",
    "        return 0.0\n",
    "    return abs(a - b) / ((a + b) / 2) * 100\n",
    "\n",
    "# Examples\n",
    "print(rpd(1.25, 1.30)) \n",
    "print(rpd(0.05, 0.05))  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50790369-b98b-498d-a566-7aa47c43f538",
   "metadata": {},
   "source": [
    " if we want to automatically detect red flags in your QC workflow, use a clean, reusable Python function that checks:\n",
    "\n",
    "- High RPD (precision failure)\n",
    "- High %Bias (accuracy failure)\n",
    "- High blank values (contamination)\n",
    "\n",
    "Any custom thresholds we define, if we want to automatically detect red flags in your QC workflow: \n",
    "- High RPD (precision failure)\n",
    "- High %Bias (accuracy failure)\n",
    "- High blank values (contamination)\n",
    "- Any custom thresholds you define\n",
    "\n",
    "#### FLAG QC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4eacaf7-c4ae-4322-9569-d92de27f8fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def qc_flag(\n",
    "    rpd_value: float = None,\n",
    "    bias_value: float = None,\n",
    "    blank_value: float = None,\n",
    "    rpd_limit: float = 20,\n",
    "    bias_limit: float = 10,\n",
    "    blank_limit: float = 0.005\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Return a QC flag based on common geochemical QA/QC thresholds.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    rpd_value : float\n",
    "        Relative Percent Difference between duplicates.\n",
    "    bias_value : float\n",
    "        Percent bias for standards.\n",
    "    blank_value : float\n",
    "        Assay value for blank samples.\n",
    "    rpd_limit : float\n",
    "        Maximum acceptable RPD (%).\n",
    "    bias_limit : float\n",
    "        Maximum acceptable %Bias (%).\n",
    "    blank_limit : float\n",
    "        Maximum acceptable blank value (same units as assay).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        QC flag: \"PASS\", \"FAIL_PRECISION\", \"FAIL_ACCURACY\",\n",
    "        \"FAIL_BLANK\", or \"MULTIPLE_FAILURES\".\n",
    "    \"\"\"\n",
    "\n",
    "    flags = []   # starts an empty list that will collect any QC problems found for that sample.\n",
    "\n",
    "    # Precision check\n",
    "    if rpd_value is not None and rpd_value > rpd_limit:\n",
    "        flags.append(\"FAIL_PRECISION\")\n",
    "\n",
    "    # Accuracy check\n",
    "    if bias_value is not None and abs(bias_value) > bias_limit:\n",
    "        flags.append(\"FAIL_ACCURACY\")\n",
    "\n",
    "    # Contamination check\n",
    "    if blank_value is not None and blank_value > blank_limit:\n",
    "        flags.append(\"FAIL_BLANK\")\n",
    "\n",
    "    # Final decision\n",
    "    if len(flags) == 0:\n",
    "        return \"PASS\"\n",
    "    if len(flags) == 1:\n",
    "        return flags[0]\n",
    "    return \"MULTIPLE_FAILURES\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d4b32f4-82e4-46fd-b92f-dd81d5d4ca84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FAIL_PRECISION\n",
      "FAIL_ACCURACY\n",
      "FAIL_BLANK\n",
      "MULTIPLE_FAILURES\n"
     ]
    }
   ],
   "source": [
    "print(qc_flag(rpd_value=25)) # FAIL_PRECISION \n",
    "print(qc_flag(bias_value=12)) # FAIL_ACCURACY \n",
    "print(qc_flag(blank_value=0.02)) # FAIL_BLANK \n",
    "print(qc_flag(rpd_value=30, bias_value=15)) # MULTIPLE_FAILURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd38e81-be99-4684-ba1c-0dead3ff76cf",
   "metadata": {},
   "source": [
    "#### QC Summary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "132fb3ac-aa17-4e23-8bbd-6191b10e1e49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SampleID</th>\n",
       "      <th>%Bias</th>\n",
       "      <th>Zscore</th>\n",
       "      <th>QC_Flag</th>\n",
       "      <th>RPD</th>\n",
       "      <th>BlankValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STD-01</td>\n",
       "      <td>12.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>MULTIPLE_FAILURES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DUP-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL_PRECISION</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLK-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL_BLANK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMP-100</td>\n",
       "      <td>2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PASS</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SampleID  %Bias  Zscore            QC_Flag   RPD  BlankValue\n",
       "0   STD-01   12.5     3.8  MULTIPLE_FAILURES   NaN         NaN\n",
       "1   DUP-15    NaN     NaN     FAIL_PRECISION  28.0         NaN\n",
       "2   BLK-03    NaN     NaN         FAIL_BLANK   NaN      0.0200\n",
       "3  SMP-100    2.1     NaN               PASS   5.2      0.0001"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# QC SUMMARY FUNCTION\n",
    "# ---------------------------------------------------------\n",
    "def qc_summary(\n",
    "    sample_id,\n",
    "    rpd_value=None,\n",
    "    bias_value=None,\n",
    "    zscore_value=None,\n",
    "    blank_value=None,\n",
    "    rpd_limit=20,\n",
    "    bias_limit=10,\n",
    "    z_limit=3,\n",
    "    blank_limit=0.005\n",
    "):\n",
    "    flags = []\n",
    "\n",
    "    if rpd_value is not None and rpd_value > rpd_limit:\n",
    "        flags.append(\"FAIL_PRECISION\")\n",
    "\n",
    "    if bias_value is not None and abs(bias_value) > bias_limit:\n",
    "        flags.append(\"FAIL_ACCURACY\")\n",
    "\n",
    "    if zscore_value is not None and abs(zscore_value) > z_limit:\n",
    "        flags.append(\"FAIL_ZSCORE\")\n",
    "\n",
    "    if blank_value is not None and blank_value > blank_limit:\n",
    "        flags.append(\"FAIL_BLANK\")\n",
    "\n",
    "    if len(flags) == 0:\n",
    "        final_flag = \"PASS\"\n",
    "    elif len(flags) == 1:\n",
    "        final_flag = flags[0]\n",
    "    else:\n",
    "        final_flag = \"MULTIPLE_FAILURES\"\n",
    "\n",
    "    row = {\n",
    "        \"SampleID\": sample_id,\n",
    "        \"RPD\": rpd_value,\n",
    "        \"%Bias\": bias_value,\n",
    "        \"Zscore\": zscore_value,\n",
    "        \"BlankValue\": blank_value,\n",
    "        \"QC_Flag\": final_flag\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame([row])\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# EXAMPLE QC ROWS\n",
    "# ---------------------------------------------------------\n",
    "df1 = qc_summary(\"STD-01\", rpd_value=None, bias_value=12.5, zscore_value=3.8)\n",
    "df2 = qc_summary(\"DUP-15\", rpd_value=28.0)\n",
    "df3 = qc_summary(\"BLK-03\", blank_value=0.02)\n",
    "df4 = qc_summary(\"SMP-100\", rpd_value=5.2, bias_value=2.1, blank_value=0.0001)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# FIX: DROP ALL-NaN COLUMNS BEFORE CONCAT\n",
    "# ---------------------------------------------------------\n",
    "clean_dfs = []\n",
    "for df in [df1, df2, df3, df4]:\n",
    "    df_clean = df.dropna(axis=1, how=\"all\")   # remove all-NaN columns\n",
    "    clean_dfs.append(df_clean)\n",
    "\n",
    "qc_table = pd.concat(clean_dfs, ignore_index=True)\n",
    "\n",
    "qc_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c2659ff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SampleID</th>\n",
       "      <th>%Bias</th>\n",
       "      <th>Zscore</th>\n",
       "      <th>QC_Flag</th>\n",
       "      <th>RPD</th>\n",
       "      <th>BlankValue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>STD-01</td>\n",
       "      <td>12.5</td>\n",
       "      <td>3.8</td>\n",
       "      <td>MULTIPLE_FAILURES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>DUP-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL_PRECISION</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BLK-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FAIL_BLANK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SMP-100</td>\n",
       "      <td>2.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PASS</td>\n",
       "      <td>5.2</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SampleID  %Bias  Zscore            QC_Flag   RPD  BlankValue\n",
       "0   STD-01   12.5     3.8  MULTIPLE_FAILURES   NaN         NaN\n",
       "1   DUP-15    NaN     NaN     FAIL_PRECISION  28.0         NaN\n",
       "2   BLK-03    NaN     NaN         FAIL_BLANK   NaN      0.0200\n",
       "3  SMP-100    2.1     NaN               PASS   5.2      0.0001"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# QC SUMMARY FUNCTION\n",
    "# ---------------------------------------------------------\n",
    "def qc_summary(\n",
    "    sample_id,\n",
    "    rpd_value=None,\n",
    "    bias_value=None,\n",
    "    zscore_value=None,\n",
    "    blank_value=None,\n",
    "    rpd_limit=20,\n",
    "    bias_limit=10,\n",
    "    z_limit=3,\n",
    "    blank_limit=0.005\n",
    "):\n",
    "    flags = []\n",
    "\n",
    "    if rpd_value is not None and rpd_value > rpd_limit:\n",
    "        flags.append(\"FAIL_PRECISION\")\n",
    "\n",
    "    if bias_value is not None and abs(bias_value) > bias_limit:\n",
    "        flags.append(\"FAIL_ACCURACY\")\n",
    "\n",
    "    if zscore_value is not None and abs(zscore_value) > z_limit:\n",
    "        flags.append(\"FAIL_ZSCORE\")\n",
    "\n",
    "    if blank_value is not None and blank_value > blank_limit:\n",
    "        flags.append(\"FAIL_BLANK\")\n",
    "\n",
    "    if len(flags) == 0:\n",
    "        final_flag = \"PASS\"\n",
    "    elif len(flags) == 1:\n",
    "        final_flag = flags[0]\n",
    "    else:\n",
    "        final_flag = \"MULTIPLE_FAILURES\"\n",
    "\n",
    "    row = {\n",
    "        \"SampleID\": sample_id,\n",
    "        \"RPD\": rpd_value,\n",
    "        \"%Bias\": bias_value,\n",
    "        \"Zscore\": zscore_value,\n",
    "        \"BlankValue\": blank_value,\n",
    "        \"QC_Flag\": final_flag\n",
    "    }\n",
    "\n",
    "    return pd.DataFrame([row])\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# EXAMPLE QC ROWS\n",
    "# ---------------------------------------------------------\n",
    "df1 = qc_summary(\"STD-01\", rpd_value=None, bias_value=12.5, zscore_value=3.8)\n",
    "df2 = qc_summary(\"DUP-15\", rpd_value=28.0)\n",
    "df3 = qc_summary(\"BLK-03\", blank_value=0.02)\n",
    "df4 = qc_summary(\"SMP-100\", rpd_value=5.2, bias_value=2.1, blank_value=0.0001)\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# FIX: DROP ALL-NaN COLUMNS BEFORE CONCAT\n",
    "# ---------------------------------------------------------\n",
    "clean_dfs = []\n",
    "for df in [df1, df2, df3, df4]:\n",
    "    df_clean = df.dropna(axis=1, how=\"all\")   # remove all-NaN columns\n",
    "    clean_dfs.append(df_clean)\n",
    "\n",
    "qc_table = pd.concat(clean_dfs, ignore_index=True)\n",
    "\n",
    "qc_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a8d207-5f13-41cc-8e30-f578e1872f55",
   "metadata": {},
   "source": [
    "### 1. QC Summary Function\n",
    "The qc_summary() function creates a singleâ€‘row DataFrame for any QC item.\n",
    "It evaluates several common QA/QC checks:\n",
    "\n",
    "- RPD â†’ precision (duplicates)\n",
    "- %Bias â†’ accuracy (standards)\n",
    "- Zâ€‘score â†’ accuracy (standards)\n",
    "- Blank value â†’ contamination (blanks)\n",
    "\n",
    "Based on these values, the function assigns a final QC flag:\n",
    "\n",
    "- \"PASS\"\n",
    "- \"FAIL_PRECISION\"\n",
    "- \"FAIL_ACCURACY\"\n",
    "- \"FAIL_ZSCORE\"\n",
    "- \"FAIL_BLANK\"\n",
    "- \"MULTIPLE_FAILURES\"\n",
    "\n",
    "The function returns a tidy oneâ€‘row DataFrame containing all metrics and the final QC decision.\n",
    "\n",
    "### 2. Creating Example QC Rows\n",
    "We generate four example QC entries:\n",
    "\n",
    "- A standard with %Bias and Zâ€‘score\n",
    "- A duplicate with RPD\n",
    "- A blank with a blank value\n",
    "- A regular sample with several QC metrics\n",
    "\n",
    "Each call to qc_summary() returns a small DataFrame representing one QC item.\n",
    "\n",
    "### 3. Cleaning QC Rows Before Combining\n",
    "Different QC types contain different fields.\n",
    "For example:\n",
    "\n",
    "- Duplicates do not have %Bias or Zâ€‘score\n",
    "- Blanks do not have RPD\n",
    "- Standards do not have blank values\n",
    "\n",
    "This means some columns are empty (all NaN) for certain rows.\n",
    "\n",
    "Before combining the rows, we remove any columns that are completely empty:\n",
    "\n",
    "`df_clean = df.dropna(axis=1, how=\"all\")`\n",
    "\n",
    "### 4. Building the Final QC Table\n",
    "All cleaned QC rows are collected into a list and concatenated:\n",
    "\n",
    "`qc_table = pd.concat(clean_dfs, ignore_index=True)`\n",
    "\n",
    "The result is a compact, readable QC summary table that shows:\n",
    "\n",
    "- Sample ID\n",
    "- Available QC metrics\n",
    "- Final QC flag\n",
    "\n",
    "This table is suitable for reporting, dashboards, or further analysis.\n",
    "\n",
    "#### Detection Limits (DL) and How to Handle Censored Data\n",
    "Analytical instruments such as ICPâ€‘MS, ICPâ€‘OES, or XRF can only `measure concentrations down to a certain minimum level`.\n",
    "**Anything below that threshold is considered Below Detection Limit (BDL) or censored data**.\n",
    "\n",
    "A **Detection Limit (DL)** `is the lowest concentration an instrument can reliably distinguish from zero.`\n",
    "If a true concentration is lower than this limit, the instrument cannot measure it accurately, so the reported value is:\n",
    "\n",
    "- None\n",
    "- 0\n",
    "- \"<DL\"\n",
    "- or a very small number that is not meaningful\n",
    "\n",
    "These values cannot be used directly in statistical analysis, so we replace them with a substitution value.\n",
    "\n",
    "**Common Substitution Methods for BDL Values**\n",
    "There are two widely used approaches in geochemistry and environmental science:\n",
    "\n",
    "1. **DL/2 (Half the detection limit)**\n",
    "A simple, conservative substitution.\n",
    "Useful when the proportion of censored data is small.\n",
    "\n",
    "2. **DL/âˆš2 (DL divided by 1.4142)**\n",
    "A statistically motivated substitution based on logâ€‘normal assumptions.\n",
    "Often used in environmental datasets.\n",
    "\n",
    "3. **Zero substitution**\n",
    "Not recommended for most geochemical work, but sometimes used in machineâ€‘learning preprocessing.\n",
    "\n",
    "The function makes this choice configurable, which is exactly what a good QC toolkit should do.\n",
    "\n",
    "##### Python Function: Substitute Belowâ€‘Detectionâ€‘Limit Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f00e629-82cf-4c96-8e7c-69f73311f6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def substitute_bdl(value: float | None, dl: float, method: str = \"half\") -> float:\n",
    "    \"\"\"\n",
    "    Substitute below-detection-limit values.\n",
    "    method: 'half' -> DL/2, 'sqrt2' -> DL / 1.4142, 'zero' -> 0\n",
    "    \"\"\"\n",
    "    if value is None or value < dl:\n",
    "        if method == \"half\":\n",
    "            return dl / 2\n",
    "        elif method == \"sqrt2\":\n",
    "            return dl / 1.41421356237\n",
    "        elif method == \"zero\":\n",
    "            return 0.0\n",
    "        else:\n",
    "            raise ValueError(\"method must be 'half', 'sqrt2', or 'zero'\")\n",
    "    return value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af363fd-8b35-4a05-86c1-824f90e181fa",
   "metadata": {},
   "source": [
    "This snipped code takes a measured value and the detection limit (dl). Checks whether the value is:\n",
    "\n",
    "- missing (None)\n",
    "- or below the detection limit\n",
    "\n",
    "If so, replace it using the chosen method:\n",
    "\n",
    "- \"half\" â†’ DL/2\n",
    "- \"sqrt2\" â†’ DL/âˆš2\n",
    "- \"zero\" â†’ 0\n",
    "\n",
    "If the value is above DL, it is returned unchanged.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcf6b9e1-968d-4840-956e-57366c51ffc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005\n",
      "0.003535533905940475\n"
     ]
    }
   ],
   "source": [
    "print(substitute_bdl(0.0003, dl=0.001, method=\"half\"))\n",
    "\n",
    "print(substitute_bdl(None, 0.005, method=\"sqrt2\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48225189-1248-4e1f-8524-4e528b8bef17",
   "metadata": {},
   "source": [
    "### Standards & Blanks QC\n",
    "Quality Control (QC) in geochemical and environmental analysis relies heavily on two special types of samples:\n",
    "\n",
    "1. `Standards` (Certified Reference Materials â€“ CRM) -->\n",
    "Standards have known, certified concentrations for each analyte.\n",
    "They are used to check accuracy of the instrument.\n",
    "\n",
    "A standard passes QC when:\n",
    "\n",
    "**%ðµð‘–ð‘Žð‘ =ð‘€ð‘’ð‘Žð‘ ð‘¢ð‘Ÿð‘’ð‘‘âˆ’ð¶ð‘’ð‘Ÿð‘¡ð‘–ð‘“ð‘–ð‘’ð‘‘ / ð¶ð‘’ð‘Ÿð‘¡ð‘–ð‘“ð‘–ð‘’ð‘‘ Ã— 100**\n",
    "\n",
    "is within an acceptable tolerance (commonly Â±10â€“20%).\n",
    "\n",
    "2. `Blanks` -->\n",
    "Blanks contain no analytes and are used to check contamination.\n",
    "\n",
    "A blank fails QC if the measured value exceeds a contamination threshold, often defined as:\n",
    "\n",
    "**Threshold = 5 Ã— DetectionÂ Limit**\n",
    "\n",
    "This ensures that any carryover or contamination is detected early.\n",
    "\n",
    "#### 1. Percent Bias Calculation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f590af60-9cc3-478e-aa0c-c157ed56c124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computes %Bias for a standard.\n",
    "# Returns NaN if the certified value is zero (to avoid division by zero).\n",
    "\n",
    "def percent_bias(measured: float, certified: float) -> float:\n",
    "    \"\"\"%Bias = (Measured - Certified) / Certified * 100.\"\"\"\n",
    "    if certified == 0:\n",
    "        return float(\"nan\")\n",
    "    return (measured - certified) / certified * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5808e54e-1b87-4493-bfcf-367725923df3",
   "metadata": {},
   "source": [
    "#### 2. Standard QC Check\n",
    "Calculates %Bias using the function above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa1b446e-89c4-4f08-a522-0e3c232a558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compares the absolute bias to a tolerance (default Â±10%).\n",
    "# Returns: the calculated bias \"PASS\" or \"FAIL\"\n",
    "\n",
    "def check_standard(measured: float, certified: float, tol_pct: float = 10.0) -> dict:\n",
    "    \"\"\"Return status and bias for a standard.\"\"\"\n",
    "    bias = percent_bias(measured, certified)\n",
    "    status = \"PASS\" if abs(bias) <= tol_pct else \"FAIL\"\n",
    "    return {\"bias_pct\": bias, \"status\": status}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba27269-1251-4745-b04f-a9311c2305e8",
   "metadata": {},
   "source": [
    "#### 3. Blank QC Check\n",
    "- Computes the contamination threshold (default = 5 Ã— DL).\n",
    "- Flags the blank as \"PASS\" if the measured value is below the threshold.\n",
    "- Flags \"FAIL\" if contamination is detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7ec3f93b-12f5-41dc-b443-8458dee22d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_blank(measured: float, dl: float, factor: float = 5.0) -> dict:\n",
    "    \"\"\"Flag contamination if measured > factor * DL.\"\"\"\n",
    "    threshold = factor * dl\n",
    "    status = \"PASS\" if measured <= threshold else \"FAIL\"\n",
    "    return {\"threshold\": threshold, \"status\": status}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7600afa-afd6-40a9-8dc2-e218cef74ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bias_pct': 1.8181818181818195, 'status': 'PASS'}\n",
      "{'threshold': 0.005, 'status': 'FAIL'}\n"
     ]
    }
   ],
   "source": [
    "print(check_standard(1.12, 1.10, tol_pct=10)) \n",
    "print(check_blank(0.006, dl=0.001, factor=5))  \n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "79e109b2-bf07-410c-a1c0-369bbaf92333",
   "metadata": {},
   "source": [
    "#### Zâ€‘Scores & Simple Shewhartâ€‘Type Control Checks\n",
    "When monitoring laboratory performance over timeâ€”especially for standards (Certified Reference Material: CRMs)â€”itâ€™s useful to track how far each measurement deviates from the certified value.\n",
    "A common way to do this is by calculating a Zâ€‘score, which expresses deviation in units of standard deviation.\n",
    "\n",
    "This is the foundation of `Shewhart control charts`, widely used in analytical chemistry to detect `drift, bias, and outâ€‘ofâ€‘control` conditions.\n",
    "\n",
    "Zâ€‘score tells you how many standard deviations a measurement is from the expected (certified) mean:\n",
    "\n",
    "##### z = (x â€“ Î¼)/Ïƒ\n",
    "Z = Measured - Mean / StDev\n",
    "\n",
    "#### 1. Zâ€‘score calculation\n",
    "- Computes the Zâ€‘score for a measurement.\n",
    "- Returns NaN if Ïƒ = 0 (to avoid division by zero).\n",
    "- This is the core metric used in control charts.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae6e421-86f2-4e5e-b8ef-b2cac235e2f2",
   "metadata": {},
   "source": [
    "#### 2. Shewhartâ€‘type control flag\n",
    "- Applies simple Shewhart rules to classify the measurement.\n",
    "- Helps identify drift or bias in the labâ€™s performance.\n",
    "- Useful for dashboards and QC summary tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c3cdfa8-07f2-47d2-ac0f-06db8fd365e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(measured: float, mu: float, sigma: float) -> float:\n",
    "    if sigma == 0:\n",
    "        return float(\"nan\")\n",
    "    return (measured - mu) / sigma\n",
    "\n",
    "def control_flag(z: float) -> str:\n",
    "    if abs(z) <= 2:\n",
    "        return \"IN CONTROL\"\n",
    "    elif abs(z) <= 3:\n",
    "        return \"WARNING (2-3Ïƒ)\"\n",
    "    else:\n",
    "        return \"OUT OF CONTROL (>3Ïƒ)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0e838a2f-8b43-4105-af3f-27a9b0cedbad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9999999999999973 IN CONTROL\n"
     ]
    }
   ],
   "source": [
    "z = z_score(1.20, mu=1.10, sigma=0.05)  # z = +2.0\n",
    "print(z, control_flag(z))               # WARNING (2-3Ïƒ)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3c1a8e3-fbfa-4984-a47e-277b2e4a5080",
   "metadata": {},
   "source": [
    "#### Interval Compositing (downhole or channel) \n",
    "Interval compositing is a data-processing method used to standardize sampling intervals along a drill hole or channel.\n",
    "It takes irregular raw samples (e.g., 0.7 m, 1.3 m, 2.1 m) and converts them into uniform intervals (e.g., 1 m composites).\n",
    "- To make datasets consistent for geostatistics, resource modelling, and machine learning\n",
    "- To reduce bias from variable sample lengths\n",
    "- To align geology, assays, and geotechnical data on the same interval grid\n",
    "\n",
    "Anything measured downhole can be composited:\n",
    "- Major elements\n",
    "- Trace elements\n",
    "- Lithology codes\n",
    "- Alteration intensities\n",
    "- Density\n",
    "- Geotech parameters\n",
    "\n",
    "This Python function performs **interval compositing**, specifically length-weighted compositing, which is the standard method used in mining and exploration to combine **multiple assay intervals into a single representative value**.\n",
    "\n",
    "We used 3 variables: (frm = start depth, to = end depth, grade = assay value (g/t, ppm, % â€” doesnâ€™t matter) )\n",
    "\n",
    "intervalâ€™s length --> length = to âˆ’ from\n",
    "\n",
    "weighted contribution of each sample -->  length Ã— grade\n",
    "\n",
    "For all samples --> âˆ‘(length Ã— grade)\n",
    "\n",
    "composite = âˆ‘(length Ã— grade) / âˆ‘length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3966ebee-6cc5-40cd-913d-6e89493102ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "def length_weighted_composite(intervals: List[Tuple[float, float, float]]) -> float:\n",
    "    \"\"\"\n",
    "    intervals: list of (from, to, grade) in g/t or ppm.\n",
    "    Returns length-weighted composite grade.\n",
    "    \"\"\"\n",
    "    total_len = 0.0\n",
    "    weighted_sum = 0.0\n",
    "    for frm, to, grade in intervals:\n",
    "        length = to - frm\n",
    "        total_len += length\n",
    "        weighted_sum += length * grade\n",
    "    return weighted_sum / total_len if total_len > 0 else float(\"nan\")\n",
    "\n",
    "# Example\n",
    "intervals = [(0, 5, 0.8), (5, 10, 1.6), (10, 15, 0.4)]\n",
    "print(length_weighted_composite(intervals)) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77fda613-ff05-4ab2-b86b-ea44eb3da0d6",
   "metadata": {},
   "source": [
    "Interval compositing is used for:\n",
    "#### âœ” Resource modelling\n",
    "Standardizing intervals to 1 m, 2 m, or bench height.\n",
    "\n",
    "#### âœ” Geostatistics\n",
    "Variograms require equalâ€‘length samples.\n",
    "\n",
    "#### âœ” Reporting\n",
    "Composites for drillhole summaries (e.g., â€œ15 m @ 0.93 g/t Auâ€).\n",
    "\n",
    "#### âœ” Multiâ€‘element analysis\n",
    "Trace elements (Bi, Te, As, Sb, Ag, etc.) are composited the same way.\n",
    "\n",
    "#### âœ” Machine learning\n",
    "Models perform better with uniform interval lengths.\n",
    "\n",
    "\n",
    "### Grade Ã— Density â†’ Metal Content (tonnes and grams)\n",
    "For a drill interval with bulk density (t/mÂ³) and width Ã— area.\n",
    "\n",
    "The function calculates:\n",
    "\n",
    "1. Volume of a rock interval\n",
    "2. Tonnes of rock (using density)\n",
    "3. Contained metal in grams (using grade)\n",
    "\n",
    "This is the classic formula:\n",
    "\n",
    "**MetalÂ (g) = Tonnes Ã— GradeÂ (g/t)**\n",
    "\n",
    "Because g/t Ã— tonnes = grams.\n",
    "\n",
    "Volume --> width_m Ã— area_m2\n",
    "\n",
    "tonnes = volume_m3 Ã— density_tpm3 --> Density is in tonnes per cubic metre (t/mÂ³).\n",
    "\n",
    "grams = tonnes Ã— grade_gpt --> Grade is in grams per tonne (g/t).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3f0bb25-08e3-476d-8091-542516b6a411",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'volume_m3': 20.0, 'tonnes': 54.0, 'metal_grams': 81.0}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def metal_content(width_m: float, area_m2: float, density_tpm3: float, grade_gpt: float) -> dict:\n",
    "    \"\"\"\n",
    "    Calculate tonnes and contained metal (grams) for a prismatic interval.\n",
    "    Assumes solid rock; ignores recovery/dilution.\n",
    "    \"\"\"\n",
    "    volume_m3 = width_m * area_m2\n",
    "    tonnes = volume_m3 * density_tpm3\n",
    "    grams = tonnes * grade_gpt  # g/t Ã— t = g\n",
    "    return {\"volume_m3\": volume_m3, \"tonnes\": tonnes, \"metal_grams\": grams}\n",
    "\n",
    "# Example: 2 m width, 10 m2 area, 2.7 t/m3 density, 1.5 g/t Au\n",
    "res = metal_content(2.0, 10.0, 2.7, 1.5)\n",
    "print(res)  # ~20 m3, 54 t, 81 g Au\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd217110-4b8c-4d4d-8fde-1c64232df701",
   "metadata": {},
   "source": [
    "Metal Content Usage: \n",
    "\n",
    "#### âœ” Resource estimation\n",
    "Tonnes and metal content per block.\n",
    "\n",
    "#### âœ” Stope design\n",
    "How much metal is in a mining slice.\n",
    "\n",
    "#### âœ” Economic evaluation\n",
    "Metal value = grams Ã— price.\n",
    "\n",
    "#### âœ” QA/QC\n",
    "Checking if composited grades make sense relative to tonnes.\n",
    "\n",
    "#### âœ” Geometallurgy\n",
    "Mass balance calculations.\n",
    "\n",
    "## Summary\n",
    "This notebook demonstrates how to implement a complete QC framework for analytical geochemistry using Python and pandas. We introduced functions for handling censored data, evaluating standards and blanks, computing Zâ€‘scores, and generating clear QC flags. Together, these tools replicate the essential checks performed in laboratory QA/QC workflows, but in a flexible, scriptable format suitable for large datasets.\n",
    "\n",
    "By combining these components, we can:\n",
    "\n",
    "- Clean and standardize raw instrument outputs\n",
    "- Automatically evaluate QC samples across all analytes\n",
    "- Detect drift, contamination, and analytical failures\n",
    "- Produce consistent QC summaries for reporting or downstream analysis\n",
    "\n",
    "This approach ensures that any subsequent interpretationâ€”statistical analysis, machine learning, or geochemical modellingâ€”is built on validated, trustworthy data. The notebook serves as a practical template for anyone working with multiâ€‘element analytical datasets who wants to bring laboratoryâ€‘grade QC into a Python environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadee8ed-dc7f-45f9-ab03-500f38fe50a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
